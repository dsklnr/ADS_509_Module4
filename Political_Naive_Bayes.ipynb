{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsklnr/ADS_509_Module4/blob/main/Political_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvqg-fgzUDPB"
      },
      "source": [
        "## Naive Bayes on Political Text\n",
        "\n",
        "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7xGqP4p1UDPD"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Feel free to include your text patterns functions\n",
        "#from text_functions_solutions import clean_tokenize, get_patterns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional imports\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import re"
      ],
      "metadata": {
        "id": "_XmxcL77YFxJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUv1gHaCZpiP",
        "outputId": "86273ead-d7cb-4b9a-8511-33899eccd806"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tZfmidG2UDPE"
      },
      "outputs": [],
      "source": [
        "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
        "convention_cur = convention_db.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a google drive connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLurWgMQXpe7",
        "outputId": "2a921b5e-ecfa-4a36-9b04-405dfad3202d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convetions_db_path = \"/content/drive/MyDrive/ADS 509/Module4/2020_Conventions.db\"\n",
        "cong_db_path = \"/content/drive/MyDrive/ADS 509/Module4/congressional_data.db\"\n",
        "os.listdir(\"/content/drive/MyDrive/ADS 509/Module4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACvImEh_X0Rv",
        "outputId": "cc417292-f979-43d7-8b95-576b094bc045"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2020_Conventions.db', 'congressional_data.db']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC-NHdRrUDPE"
      },
      "source": [
        "### Part 1: Exploratory Naive Bayes\n",
        "\n",
        "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text\n",
        "for each party and prepare it for use in Naive Bayes.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean and tokenize text\n",
        "def clean_and_tokenize(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Return the cleaned text as a single string\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "sEmKcSoSaRKe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5hf83uSUDPE",
        "outputId": "6e3e804f-57cc-4500-d020-60b5191965d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['skip content company careers press freelancers blog services transcription captions foreign subtitles translation freelancers contact login return transcript library home transcript categories transcripts election transcripts classic speech transcripts congressional testimony hearing transcripts debate transcripts donald trump transcripts entertainment transcripts financial transcripts interview transcripts political transcripts press conference transcripts speech transcripts sports transcripts technology transcripts aug democratic national convention dnc night transcript rev blog transcripts election transcripts democratic national convention dnc night transcript night democratic national convention dnc august read full transcript event transcribe content try rev free save time transcribing captioning subtitling', 'Democratic']\n",
            "['im calling full session th quadrennial national convention democratic party order welcome final session historic memorable convention weve called th quadrennial democratic national convention order', 'Democratic']\n",
            "['every four years come together reaffirm democracy year weve come save', 'Democratic']\n",
            "['fight perfect union fighting soul country lives right fight real', 'Democratic']\n",
            "['must come together defeat donald trump elect joe biden kamala harris next president vice president', 'Democratic']\n"
          ]
        }
      ],
      "source": [
        "# Create a conventions db connection\n",
        "convention_db = sqlite3.connect(convetions_db_path)\n",
        "convention_cur = convention_db.cursor()\n",
        "\n",
        "# Create a list to hold cleaned text and party data\n",
        "convention_data = []\n",
        "\n",
        "# Query data\n",
        "query_results = convention_cur.execute(\n",
        "                            '''\n",
        "                            SELECT text, party FROM conventions\n",
        "                            ''')\n",
        "\n",
        "# Add clean text to the convention_data list\n",
        "for row in query_results :\n",
        "    text, party = row\n",
        "    cleaned_text = clean_and_tokenize(text)\n",
        "    convention_data.append([cleaned_text, party])\n",
        "\n",
        "# Close the connection\n",
        "convention_db.close()\n",
        "\n",
        "# Display the first 5 items\n",
        "for data in convention_data[:5]:\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15rfTPXSUDPE"
      },
      "source": [
        "Let's look at some random entries and see if they look right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jA1HPqqUDPF",
        "outputId": "c74c5d11-20d5-49ac-d6d0-527f53572749"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['different kind convention', 'Democratic'],\n",
              " ['know bidens america arent opportunity zones administration actually looks government private enterprise work together donald trump fight deliver better future women americans remember wonderful victory one century ago',\n",
              "  'Republican'],\n",
              " ['guiding purpose house democrats fighting people sent senate bills lower healthcare costs bigger paychecks cleaner government protecting john lewis voting rights enacting george floyd justice policing act weve sent senate bills protect dreamers lgbtq equality prevent gun violence preserve planet future generations even possible america standing way mitch mcconnell donald trump',\n",
              "  'Democratic'],\n",
              " ['name dan scavino years old got parttime job golf course outside new york city one day cleaning golf clubs man pulled parking lot wasnt single person didnt know everyones jaws ground donald trump could think nobody ever believe school tomorrow never would imagined moment ive president trumps side almost years years later theres part still feels sense wonder every day consider journey taken together taken many watching tonight personal story donald trump many ways saw potential spark possibility could achieve even thought possible thats views country also scratched surface together',\n",
              "  'Republican'],\n",
              " ['important moment melania trump really prominent week', 'Republican']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "random.choices(convention_data,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssGSZjisUDPF"
      },
      "source": [
        "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfihs6aiUDPF",
        "outputId": "47323fe5-a332-42df-d84e-6b9a5ffff885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With a word cutoff of 5, we have 2328 as features in the model.\n"
          ]
        }
      ],
      "source": [
        "word_cutoff = 5\n",
        "\n",
        "tokens = [w for t, p in convention_data for w in t.split()]\n",
        "\n",
        "word_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "feature_words = set()\n",
        "\n",
        "for word, count in word_dist.items() :\n",
        "    if count > word_cutoff :\n",
        "        feature_words.add(word)\n",
        "\n",
        "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kRoNGiHSUDPF"
      },
      "outputs": [],
      "source": [
        "def conv_features(text,fw) :\n",
        "    # create a dictionary\n",
        "    ret_dict = {}\n",
        "\n",
        "    # Split the text into tokens\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Iterate through the feature words and check if they are present in the tokens\n",
        "    for word in fw:\n",
        "        if word in tokens:\n",
        "            ret_dict[word] = True  # Add the word to the dictionary with value True\n",
        "\n",
        "    return ret_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dX9qbV2zUDPG"
      },
      "outputs": [],
      "source": [
        "assert(len(feature_words)>0)\n",
        "assert(conv_features(\"donald is the president\",feature_words)==\n",
        "       {'donald':True,'president':True})\n",
        "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
        "                     {'people':True,'america':True,\"citizens\":True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWm1E7i4UDPG"
      },
      "source": [
        "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PXIWFw4uUDPG"
      },
      "outputs": [],
      "source": [
        "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gh7CqPsuUDPG"
      },
      "outputs": [],
      "source": [
        "random.seed(20220507)\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "test_size = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-JjXnABUDPG",
        "outputId": "c0a0eb15-767e-46fb-fec9-2d4c92c56b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.494\n"
          ]
        }
      ],
      "source": [
        "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSaeYTsqUDPG",
        "outputId": "e290b4d2-f730-40a2-86d9-63a1c417e969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                   china = True           Republ : Democr =     25.8 : 1.0\n",
            "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
            "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
            "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
            "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
            "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
            "                supports = True           Republ : Democr =     17.1 : 1.0\n",
            "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
            "                   media = True           Republ : Democr =     14.9 : 1.0\n",
            "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
            "               countries = True           Republ : Democr =     13.0 : 1.0\n",
            "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
            "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
            "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
            "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
            "                religion = True           Republ : Democr =     13.0 : 1.0\n",
            "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
            "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
            "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
            "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
            "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
            "              department = True           Republ : Democr =     10.9 : 1.0\n",
            "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
            "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
            "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
          ]
        }
      ],
      "source": [
        "classifier.show_most_informative_features(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtsWWxFrUDPG"
      },
      "source": [
        "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
        "\n",
        "### My Observations\n",
        "\n",
        "It's interesting to see which words our Naive Bayes model associates with democrat or republican. The words shown above are all highly associated with repbulican as seen by the republican democrat ratios. For example the republican democrat ratio for the word China is 25.8 : 1. However, it is also important to note that our Naive Bayes model has a 49.4% accuracy when classifying our test data set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSbxm5ZmUDPG"
      },
      "source": [
        "## Part 2: Classifying Congressional Tweets\n",
        "\n",
        "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
        "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
        "give you the query I used to pull out the tweets. Note that this DB has some big tables and\n",
        "is unindexed, so the query takes a minute or two to run on my machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FWwVIXgkUDPH"
      },
      "outputs": [],
      "source": [
        "# Create a congress db connection\n",
        "cong_db = sqlite3.connect(cong_db_path)\n",
        "cong_cur = cong_db.cursor()\n",
        "\n",
        "# Query tweets\n",
        "results = cong_cur.execute(\n",
        "        '''\n",
        "           SELECT DISTINCT\n",
        "                  cd.candidate,\n",
        "                  cd.party,\n",
        "                  tw.tweet_text\n",
        "           FROM candidate_data cd\n",
        "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle\n",
        "               AND cd.candidate == tw.candidate\n",
        "               AND cd.district == tw.district\n",
        "           WHERE cd.party in ('Republican','Democratic')\n",
        "               AND tw.tweet_text NOT LIKE '%RT%'\n",
        "        ''')\n",
        "\n",
        "results = list(results) # Just to store it, since the query is time consuming\n",
        "\n",
        "# Close the connection\n",
        "cong_db.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 results\n",
        "for data in results[:5]:\n",
        "    print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6cvcwPioooo",
        "outputId": "72f3e5bf-7ccd-4555-da65-e9c3e4a4cdf3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Mo Brooks', 'Republican', b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq')\n",
            "('Mo Brooks', 'Republican', b'\"Brooks: I Do Not Support America Raising, Training, and Arming a \\nRebel Army to Fight in Syria\\xe2\\x80\\x99s Civil War\" http://t.co/f2QFErMkD4')\n",
            "('Mo Brooks', 'Republican', b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6')\n",
            "('Mo Brooks', 'Republican', b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA')\n",
            "('Mo Brooks', 'Republican', b'\"Rep. Mo Brooks: NDAA Amnesty Amendment \\xe2\\x80\\x98Betrays Americans\\xe2\\x80\\x99\" via @BreitbartNews http://t.co/aflHYdUkuF')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the list to hold tweet data\n",
        "tweet_data = []\n",
        "\n",
        "# Define the set of stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Process each tweet in the results\n",
        "for candidate, party, tweet_text in results:\n",
        "    # Decode tweet_text if it's in bytes\n",
        "    if isinstance(tweet_text, bytes):\n",
        "        tweet_text = tweet_text.decode('utf-8')\n",
        "\n",
        "    # Clean and tokenize the tweet text\n",
        "    tokens = tweet_text.lower().split()\n",
        "    cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Join the cleaned tokens back into a single string\n",
        "    cleaned_text = ' '.join(cleaned_tokens)\n",
        "\n",
        "    # Append the cleaned text and party to the tweet_data list\n",
        "    tweet_data.append([cleaned_text, party])"
      ],
      "metadata": {
        "id": "-2KUU5LRm7Jf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 results\n",
        "for data in tweet_data[:5]:\n",
        "    print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2biqA5VoLiO",
        "outputId": "24b5eb98-b041-4606-c307-189c668ecaf3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"brooks joins alabama delegation voting flawed funding bill\" http://t.co/3cwjiwysnq', 'Republican']\n",
            "['\"brooks: support america raising, training, arming rebel army fight syriaâ€™s civil war\" http://t.co/f2qfermkd4', 'Republican']\n",
            "['\"brooks: senate democrats allowing president give americansâ€™ jobs illegals\" #securetheborder https://t.co/mzteax8xs6', 'Republican']\n",
            "['\"nasa square\" event sat. 11am â€“ 4pm. stop &amp; hear incredible work done #al05! @downtownhsv http://t.co/r9zy8wmepa', 'Republican']\n",
            "['\"rep. mo brooks: ndaa amnesty amendment â€˜betrays americansâ€™\" via @breitbartnews http://t.co/aflhydukuf', 'Republican']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnbAnUNJUDPH"
      },
      "source": [
        "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "L7PwAQHTUDPH"
      },
      "outputs": [],
      "source": [
        "random.seed(20201014)\n",
        "\n",
        "tweet_data_sample = random.choices(tweet_data,k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBykDndnUDPH",
        "outputId": "6aa9a3eb-203e-4891-dd6d-a85f93d95823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's our (cleaned) tweet: mass shooting las vegas horrific act violence. victims families thoughts prayers.\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: early morning #traveltuesday. leaving ok-02 dc! http://t.co/igknci79e7\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: moderates #iraq &amp; #syria civilians. we've enemies sides conflict. assist either.\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: rt @natsecaction: 200 national security veterans demanding answers release confidential national security questionnaâ€¦\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: ðŸ’¯%, #buildthatwall now!! https://t.co/hyb6jcw5ea\n",
            "Actual party is Republican and our classifer says Democratic.\n",
            "\n",
            "Here's our (cleaned) tweet: glad attend #g20 assure everyone could majority americans still stand traditional allies.\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: @cnn everyone wraps flag patriotism avoid discussion racism injustice. kneeling honoring troops\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: applaud president trump's decision send national guard protect border. congress support president including fully funding wall. time stop playing politics national security united states. #fundthewall #nationalguard\n",
            "Actual party is Republican and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: congress considers disaster relief spending year, must include funding california fire relief. listen remarks house floor, here: https://t.co/mpkbk1m7s5\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: proud support. oss helped vanquish malevolent enemies countryâ€” free worldâ€” ever faced. https://t.co/8vyiaviftt\n",
            "Actual party is Democratic and our classifer says Republican.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for tweet, party in tweet_data_sample :\n",
        "    tweet_features = conv_features(tweet,feature_words)\n",
        "    estimated_party = classifier.classify(tweet_features)\n",
        "\n",
        "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
        "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfRmMvAxUDPH"
      },
      "source": [
        "Now that we've looked at it some, let's score a bunch and see how we're doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "alqUDnX0UDPH"
      },
      "outputs": [],
      "source": [
        "# dictionary of counts by actual party and estimated party.\n",
        "# first key is actual, second is estimated\n",
        "parties = ['Republican','Democratic']\n",
        "results = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for p in parties :\n",
        "    for p1 in parties :\n",
        "        results[p][p1] = 0\n",
        "\n",
        "\n",
        "num_to_score = 10000\n",
        "random.shuffle(tweet_data)\n",
        "\n",
        "for idx, tp in enumerate(tweet_data) :\n",
        "    tweet, party = tp\n",
        "    # Now do the same thing as above, but we store the results rather\n",
        "    # than printing them.\n",
        "\n",
        "    # get the estimated party\n",
        "    tweet_features = conv_features(tweet,feature_words)\n",
        "    estimated_party = classifier.classify(tweet_features)\n",
        "\n",
        "    results[party][estimated_party] += 1\n",
        "\n",
        "    if idx > num_to_score :\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "m-gVN4drUDPH",
        "outputId": "9b2ba9d8-9514-4e55-88f0-21146ae84e9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>()>,\n",
              "            {'Republican': defaultdict(int,\n",
              "                         {'Republican': 3397, 'Democratic': 672}),\n",
              "             'Democratic': defaultdict(int,\n",
              "                         {'Republican': 4924, 'Democratic': 1009})})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjtAx6eEUDPH"
      },
      "source": [
        "### Reflections\n",
        "\n",
        "Here we can see a basic confusion matrix for republican and democrat party predictions based on the twitter text.  We can see that 3,397 republicans and 1,009 democrats were correctly predicted (true positives). However, 672 democrats and 4,924 republicans were incorrectly classified (false positives). Viewing these results, it is important to see that the dataset is quite imbalanced with republicans and democrats. There are far less democrats than republicans in the twitter dataset."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}