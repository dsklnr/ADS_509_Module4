{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsklnr/ADS_509_Module4/blob/main/Political_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvqg-fgzUDPB"
      },
      "source": [
        "## Naive Bayes on Political Text\n",
        "\n",
        "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7xGqP4p1UDPD"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Feel free to include your text patterns functions\n",
        "#from text_functions_solutions import clean_tokenize, get_patterns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional imports\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import re"
      ],
      "metadata": {
        "id": "_XmxcL77YFxJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUv1gHaCZpiP",
        "outputId": "0600ed5b-413e-4a19-e967-7a5070fde061"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tZfmidG2UDPE"
      },
      "outputs": [],
      "source": [
        "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
        "convention_cur = convention_db.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a google drive connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLurWgMQXpe7",
        "outputId": "fd8bf616-1baf-460f-889e-5b0ff8ac1a37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convetions_db_path = \"/content/drive/MyDrive/ADS 509/Module4/2020_Conventions.db\"\n",
        "cong_db_path = \"/content/drive/MyDrive/ADS 509/Module4/congressional_data.db\"\n",
        "os.listdir(\"/content/drive/MyDrive/ADS 509/Module4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACvImEh_X0Rv",
        "outputId": "48fe5d2b-8b92-41f7-f3d3-808a6ab7a680"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2020_Conventions.db', 'congressional_data.db']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC-NHdRrUDPE"
      },
      "source": [
        "### Part 1: Exploratory Naive Bayes\n",
        "\n",
        "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text\n",
        "for each party and prepare it for use in Naive Bayes.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean and tokenize text\n",
        "def clean_and_tokenize(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and non-alphabetic characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Return the cleaned text as a single string\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "sEmKcSoSaRKe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5hf83uSUDPE",
        "outputId": "c83eddcf-0e70-4ac8-f7db-192716f5517a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['skip content company careers press freelancers blog services transcription captions foreign subtitles translation freelancers contact login return transcript library home transcript categories transcripts election transcripts classic speech transcripts congressional testimony hearing transcripts debate transcripts donald trump transcripts entertainment transcripts financial transcripts interview transcripts political transcripts press conference transcripts speech transcripts sports transcripts technology transcripts aug democratic national convention dnc night transcript rev blog transcripts election transcripts democratic national convention dnc night transcript night democratic national convention dnc august read full transcript event transcribe content try rev free save time transcribing captioning subtitling', 'Democratic']\n",
            "['im calling full session th quadrennial national convention democratic party order welcome final session historic memorable convention weve called th quadrennial democratic national convention order', 'Democratic']\n",
            "['every four years come together reaffirm democracy year weve come save', 'Democratic']\n",
            "['fight perfect union fighting soul country lives right fight real', 'Democratic']\n",
            "['must come together defeat donald trump elect joe biden kamala harris next president vice president', 'Democratic']\n"
          ]
        }
      ],
      "source": [
        "# Create a conventions db connection\n",
        "convention_db = sqlite3.connect(convetions_db_path)\n",
        "convention_cur = convention_db.cursor()\n",
        "\n",
        "# Create a list to hold cleaned text and party data\n",
        "convention_data = []\n",
        "\n",
        "# Query data\n",
        "query_results = convention_cur.execute(\n",
        "                            '''\n",
        "                            SELECT text, party FROM conventions\n",
        "                            ''')\n",
        "\n",
        "# Add clean text to the convention_data list\n",
        "for row in query_results :\n",
        "    text, party = row\n",
        "    cleaned_text = clean_and_tokenize(text)\n",
        "    convention_data.append([cleaned_text, party])\n",
        "\n",
        "# Close the connection\n",
        "convention_db.close()\n",
        "\n",
        "# Display the first 5 items\n",
        "for data in convention_data[:5]:\n",
        "    print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15rfTPXSUDPE"
      },
      "source": [
        "Let's look at some random entries and see if they look right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jA1HPqqUDPF",
        "outputId": "141776c1-d86b-42c3-b602-0a16b38d19b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['yes', 'Republican'],\n",
              " ['official roll call business republican convention conducted today charlotte created short video symbolize excitement president trump across states territories thank watching god bless god bless united states america',\n",
              "  'Republican'],\n",
              " ['david never never coming back murdered people didnt know didnt care would done anything help violence destruction legitimate forms protest safeguard black lives destroy president trump understands offered federal help restore order communities time police departments short resources manpower need help accept help must heal affect change cannot heal amid devastation chaos president trump knows need davids communities fewer need come together peace remember every life precious jaron smith good evening im ben carson retired neurosurgeon public servant begin id like say hearts go blake family families whove impacted tragic events kenosha jacobs mother urged country lets use hearts love intelligence work together show rest world humans supposed treat america great behave greatly jaron smith order succeed change must first come together love fellow citizens history reminds us necessary change comes hope love senseless destructive violence abraham lincoln said america divided purpose plainly stated destroy government unless allowed construe enforce constitution please points dispute us rule ruin events jaron smith words warning relevant today choice want big government controls lives cradle grave believe power wisdom people ability selfgovern help limited federal government president donald j trump believes people one us makes promises keeps transparent certainly know hes thinking submit political correctness towards enforces media real jaron smith right need real need courage cant cower corner hope one calls us name believing keep us safe courage lead us good place must remember sacrificed everything order give us freedom must willing come us jaron smith president trump dabble identity politics wants everyone succeed believes adage rising tide lifts boats many side love incite division claiming president trump racist could wrong years ago jesse jackson gave donald trump award economic opportunities created black people palm beach florida donald trump led crusade allow blacks jews private clubs resorts jaron smith one first things president bring office historically black colleges universities white house could get proper attention financial support pandemic african american unemployment time low president trump accomplished prison reform created incentives encourage investors become involved economically deprived areas america jaron smith strongly supports school choice fully recognizing matter circumstances person born achieve success good education true mother forced read books doctors entrepreneurs inventors scientists began recognize person happens life mother always told ben anything never allow become victim stopped listening people trying convince victim others responsible victimhood jaron smith racist fact africanamericans highest abortion rate president trump prolife president countrys history continue fight cannot yet speak vision shining city upon hill came jesuss sermon mount america shiny city beacon hope world moment time president donald trump man courage vision ability keep shining brightly',\n",
              "  'Republican'],\n",
              " ['think places make neighborhood feel like home barbershop catch latest neighborhood news get hair cut restaurant know order heart art studio creative guy great idea ton hustle turned abandoned building second home entire community economists tell small businesses like one critically important recovery theyre also plain important without places call home wouldnt thats thing joe biden understands donald trump never never talk economy stock market whether find work really means something instead feeling like youre supposed grateful get paycheck rep',\n",
              "  'Democratic'],\n",
              " ['convention joe biden guy earned respect commands across world across aisle stakes election call kind leadership think one party think core democracy thats youre hear unexpected voices',\n",
              "  'Democratic']]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "random.choices(convention_data,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssGSZjisUDPF"
      },
      "source": [
        "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfihs6aiUDPF",
        "outputId": "df3c0bed-abc4-48e9-d13c-9a85b2ab9d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With a word cutoff of 5, we have 2328 as features in the model.\n"
          ]
        }
      ],
      "source": [
        "word_cutoff = 5\n",
        "\n",
        "tokens = [w for t, p in convention_data for w in t.split()]\n",
        "\n",
        "word_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "feature_words = set()\n",
        "\n",
        "for word, count in word_dist.items() :\n",
        "    if count > word_cutoff :\n",
        "        feature_words.add(word)\n",
        "\n",
        "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kRoNGiHSUDPF"
      },
      "outputs": [],
      "source": [
        "def conv_features(text,fw) :\n",
        "    # create a dictionary\n",
        "    ret_dict = {}\n",
        "\n",
        "    # Split the text into tokens\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Iterate through the feature words and check if they are present in the tokens\n",
        "    for word in fw:\n",
        "        if word in tokens:\n",
        "            ret_dict[word] = True  # Add the word to the dictionary with value True\n",
        "\n",
        "    return ret_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dX9qbV2zUDPG"
      },
      "outputs": [],
      "source": [
        "assert(len(feature_words)>0)\n",
        "assert(conv_features(\"donald is the president\",feature_words)==\n",
        "       {'donald':True,'president':True})\n",
        "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
        "                     {'people':True,'america':True,\"citizens\":True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWm1E7i4UDPG"
      },
      "source": [
        "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PXIWFw4uUDPG"
      },
      "outputs": [],
      "source": [
        "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Gh7CqPsuUDPG"
      },
      "outputs": [],
      "source": [
        "random.seed(20220507)\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "test_size = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-JjXnABUDPG",
        "outputId": "2aaf239d-c5c5-42ea-8ccf-21a70c1ade42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.494\n"
          ]
        }
      ],
      "source": [
        "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSaeYTsqUDPG",
        "outputId": "3024e72f-e6a5-4510-9ee2-d1a457dd08b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                   china = True           Republ : Democr =     25.8 : 1.0\n",
            "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
            "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
            "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
            "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
            "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
            "                supports = True           Republ : Democr =     17.1 : 1.0\n",
            "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
            "                   media = True           Republ : Democr =     14.9 : 1.0\n",
            "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
            "               countries = True           Republ : Democr =     13.0 : 1.0\n",
            "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
            "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
            "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
            "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
            "                religion = True           Republ : Democr =     13.0 : 1.0\n",
            "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
            "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
            "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
            "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
            "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
            "              department = True           Republ : Democr =     10.9 : 1.0\n",
            "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
            "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
            "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
          ]
        }
      ],
      "source": [
        "classifier.show_most_informative_features(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtsWWxFrUDPG"
      },
      "source": [
        "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
        "\n",
        "### My Observations\n",
        "\n",
        "_Your observations to come._\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSbxm5ZmUDPG"
      },
      "source": [
        "## Part 2: Classifying Congressional Tweets\n",
        "\n",
        "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
        "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
        "give you the query I used to pull out the tweets. Note that this DB has some big tables and\n",
        "is unindexed, so the query takes a minute or two to run on my machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FWwVIXgkUDPH"
      },
      "outputs": [],
      "source": [
        "# Create a congress db connection\n",
        "cong_db = sqlite3.connect(cong_db_path)\n",
        "cong_cur = cong_db.cursor()\n",
        "\n",
        "# Query tweets\n",
        "results = cong_cur.execute(\n",
        "        '''\n",
        "           SELECT DISTINCT\n",
        "                  cd.candidate,\n",
        "                  cd.party,\n",
        "                  tw.tweet_text\n",
        "           FROM candidate_data cd\n",
        "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle\n",
        "               AND cd.candidate == tw.candidate\n",
        "               AND cd.district == tw.district\n",
        "           WHERE cd.party in ('Republican','Democratic')\n",
        "               AND tw.tweet_text NOT LIKE '%RT%'\n",
        "        ''')\n",
        "\n",
        "results = list(results) # Just to store it, since the query is time consuming\n",
        "\n",
        "# Close the connection\n",
        "cong_db.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 results\n",
        "for data in results[:5]:\n",
        "    print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6cvcwPioooo",
        "outputId": "21d82801-e7e2-4f44-9c63-a0b9554476e8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Mo Brooks', 'Republican', b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq')\n",
            "('Mo Brooks', 'Republican', b'\"Brooks: I Do Not Support America Raising, Training, and Arming a \\nRebel Army to Fight in Syria\\xe2\\x80\\x99s Civil War\" http://t.co/f2QFErMkD4')\n",
            "('Mo Brooks', 'Republican', b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6')\n",
            "('Mo Brooks', 'Republican', b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA')\n",
            "('Mo Brooks', 'Republican', b'\"Rep. Mo Brooks: NDAA Amnesty Amendment \\xe2\\x80\\x98Betrays Americans\\xe2\\x80\\x99\" via @BreitbartNews http://t.co/aflHYdUkuF')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the list to hold tweet data\n",
        "tweet_data = []\n",
        "\n",
        "# Define the set of stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Process each tweet in the results\n",
        "for candidate, party, tweet_text in results:\n",
        "    # Decode tweet_text if it's in bytes\n",
        "    if isinstance(tweet_text, bytes):\n",
        "        tweet_text = tweet_text.decode('utf-8')\n",
        "\n",
        "    # Clean and tokenize the tweet text\n",
        "    tokens = tweet_text.lower().split()\n",
        "    cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Join the cleaned tokens back into a single string\n",
        "    cleaned_text = ' '.join(cleaned_tokens)\n",
        "\n",
        "    # Append the cleaned text and party to the tweet_data list\n",
        "    tweet_data.append([cleaned_text, party])"
      ],
      "metadata": {
        "id": "-2KUU5LRm7Jf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 results\n",
        "for data in tweet_data[:5]:\n",
        "    print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2biqA5VoLiO",
        "outputId": "058c53f8-7431-40c3-b6dc-127210128124"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"brooks joins alabama delegation voting flawed funding bill\" http://t.co/3cwjiwysnq', 'Republican']\n",
            "['\"brooks: support america raising, training, arming rebel army fight syria’s civil war\" http://t.co/f2qfermkd4', 'Republican']\n",
            "['\"brooks: senate democrats allowing president give americans’ jobs illegals\" #securetheborder https://t.co/mzteax8xs6', 'Republican']\n",
            "['\"nasa square\" event sat. 11am – 4pm. stop &amp; hear incredible work done #al05! @downtownhsv http://t.co/r9zy8wmepa', 'Republican']\n",
            "['\"rep. mo brooks: ndaa amnesty amendment ‘betrays americans’\" via @breitbartnews http://t.co/aflhydukuf', 'Republican']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnbAnUNJUDPH"
      },
      "source": [
        "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "L7PwAQHTUDPH"
      },
      "outputs": [],
      "source": [
        "random.seed(20201014)\n",
        "\n",
        "tweet_data_sample = random.choices(tweet_data,k=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature words based on token frequency\n",
        "word_cutoff = 5\n",
        "tokens = [word for cleaned_text, _ in tweet_data for word in cleaned_text.split()]\n",
        "word_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "feature_words = {word for word, count in word_dist.items() if count > word_cutoff}\n",
        "\n",
        "# Prepare the featuresets\n",
        "featuresets = [(conv_features(cleaned_text, feature_words), party) for cleaned_text, party in tweet_data]\n",
        "\n",
        "# Shuffle the featuresets\n",
        "random.seed(20220507)\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "# Split into train and test sets\n",
        "test_size = 500\n",
        "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
        "\n",
        "# Train the classifier\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Create a random sample to predict party type\n",
        "random.seed(20201014)\n",
        "tweet_data_sample = random.choices(tweet_data, k=10)\n",
        "\n",
        "# Prepare for predictions\n",
        "for cleaned_text, actual_party in tweet_data_sample:\n",
        "    features = conv_features(cleaned_text.split(), feature_words)\n",
        "    estimated_party = classifier.classify(features)\n",
        "\n",
        "    print(f\"Here's our (cleaned) tweet: {cleaned_text}\")\n",
        "    print(f\"Actual party is {actual_party} and our classifier says {estimated_party}.\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "raBAwr4msQ9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBykDndnUDPH",
        "outputId": "8f7c6726-fe7b-4d17-a36d-5a55d2f9d59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's our (cleaned) tweet: mass shooting las vegas horrific act violence. victims families thoughts prayers.\n",
            "Actual party is Democratic and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: early morning #traveltuesday. leaving ok-02 dc! http://t.co/igknci79e7\n",
            "Actual party is Republican and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: moderates #iraq &amp; #syria civilians. we've enemies sides conflict. assist either.\n",
            "Actual party is Republican and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: rt @natsecaction: 200 national security veterans demanding answers release confidential national security questionna…\n",
            "Actual party is Democratic and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: 💯%, #buildthatwall now!! https://t.co/hyb6jcw5ea\n",
            "Actual party is Republican and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: glad attend #g20 assure everyone could majority americans still stand traditional allies.\n",
            "Actual party is Democratic and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: @cnn everyone wraps flag patriotism avoid discussion racism injustice. kneeling honoring troops\n",
            "Actual party is Democratic and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: applaud president trump's decision send national guard protect border. congress support president including fully funding wall. time stop playing politics national security united states. #fundthewall #nationalguard\n",
            "Actual party is Republican and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: congress considers disaster relief spending year, must include funding california fire relief. listen remarks house floor, here: https://t.co/mpkbk1m7s5\n",
            "Actual party is Democratic and our classifer says Gotta fill this in.\n",
            "\n",
            "Here's our (cleaned) tweet: proud support. oss helped vanquish malevolent enemies country— free world— ever faced. https://t.co/8vyiaviftt\n",
            "Actual party is Democratic and our classifer says Gotta fill this in.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for tweet, party in tweet_data_sample :\n",
        "    estimated_party = 'Gotta fill this in'\n",
        "    # Fill in the right-hand side above with code that estimates the actual party\n",
        "\n",
        "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
        "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
        "    print(\"\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfRmMvAxUDPH"
      },
      "source": [
        "Now that we've looked at it some, let's score a bunch and see how we're doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alqUDnX0UDPH"
      },
      "outputs": [],
      "source": [
        "# dictionary of counts by actual party and estimated party.\n",
        "# first key is actual, second is estimated\n",
        "parties = ['Republican','Democratic']\n",
        "results = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for p in parties :\n",
        "    for p1 in parties :\n",
        "        results[p][p1] = 0\n",
        "\n",
        "\n",
        "num_to_score = 10000\n",
        "random.shuffle(tweet_data)\n",
        "\n",
        "for idx, tp in enumerate(tweet_data) :\n",
        "    tweet, party = tp\n",
        "    # Now do the same thing as above, but we store the results rather\n",
        "    # than printing them.\n",
        "\n",
        "    # get the estimated party\n",
        "    estimated_party = \"Gotta fill this in\"\n",
        "\n",
        "    results[party][estimated_party] += 1\n",
        "\n",
        "    if idx > num_to_score :\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-gVN4drUDPH"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjtAx6eEUDPH"
      },
      "source": [
        "### Reflections\n",
        "\n",
        "_Write a little about what you see in the results_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}